{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fe740bd-d5be-4b90-bffc-a3bc82b93a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'MedViT'...\n",
      "remote: Enumerating objects: 146, done.\u001b[K\n",
      "remote: Counting objects: 100% (145/145), done.\u001b[K\n",
      "remote: Compressing objects: 100% (80/80), done.\u001b[K\n",
      "remote: Total 146 (delta 70), reused 125 (delta 57), pack-reused 1\u001b[K\n",
      "Receiving objects: 100% (146/146), 804.62 KiB | 3.87 MiB/s, done.\n",
      "Resolving deltas: 100% (70/70), done.\n"
     ]
    }
   ],
   "source": [
    "# Install MedViT\n",
    "!git clone https://github.com/Omid-Nejati/MedViT.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8fb8848-e455-40a1-a5e9-85eab4fcc4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" # is needed for hachiko\n",
    "\n",
    "from PIL import Image\n",
    "import torch\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from typing import Tuple\n",
    "\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "import json\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from validation_utils import custom_dataset, plot_confusion_matrix, get_trainer, get_compute_metrics\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c68a77f",
   "metadata": {},
   "source": [
    "## MedViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6c79a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_name = 'MedViT512_tr35_stage6(3)_CCropSpot2HTrivAug_fastvitprepr_lr1e5'\n",
    "dataset_name = 'DDR'\n",
    "prepared_ds_test = custom_dataset(pretrained_model_name)\n",
    "compute_metrics = get_compute_metrics(pretrained_model_name, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9901d1e-81a8-4c1b-adbb-2ea8fceb9224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized with random weights:\n",
      "initialize_weights...\n"
     ]
    }
   ],
   "source": [
    "# Initialise a MedViT class\n",
    "from transformers import PreTrainedModel\n",
    "from MedViT.MedViT import MedViT, MedViT_large\n",
    "\n",
    "# Define configuration\n",
    "from transformers import PretrainedConfig\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class MedViTConfig(PretrainedConfig):\n",
    "    model_type = \"medvit\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        stem_chs: List[int] = [64, 32, 64],\n",
    "        depths: List[int] = [3, 4, 30, 3],\n",
    "        path_dropout: float = 0.2,\n",
    "        attn_drop: int = 0,\n",
    "        drop: int = 0,\n",
    "        num_classes: int = 5,\n",
    "        strides: List[int] = [1, 2, 2, 2],\n",
    "        sr_ratios: List[int] = [8, 4, 2, 1],\n",
    "        head_dim: int = 32,\n",
    "        mix_block_ratio: float = 0.75,\n",
    "        use_checkpoint: bool = False,\n",
    "        pretrained: bool = False,\n",
    "        pretrained_cfg: str = None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        self.stem_chs = stem_chs\n",
    "        self.depths = depths\n",
    "        self.path_dropout = path_dropout\n",
    "        self.attn_drop = attn_drop\n",
    "        self.drop = drop\n",
    "        self.num_classes = num_classes\n",
    "        self.strides = strides\n",
    "        self.sr_ratios = sr_ratios\n",
    "        self.head_dim = head_dim\n",
    "        self.mix_block_ratio = mix_block_ratio\n",
    "        self.use_checkpoint = use_checkpoint\n",
    "        self.pretrained = pretrained,\n",
    "        self.pretrained_cfg = pretrained_cfg\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "class MedViTClassification(PreTrainedModel):\n",
    "    config_class = MedViTConfig\n",
    "\n",
    "    def __init__(self, config, pretrained=False):\n",
    "        super().__init__(config)\n",
    "\n",
    "        if pretrained is False:\n",
    "          print('Initialized with random weights:')\n",
    "          self.model = MedViT(\n",
    "          stem_chs = config.stem_chs,\n",
    "          depths = config.depths,\n",
    "          path_dropout = config.path_dropout,\n",
    "          attn_drop = config.attn_drop,\n",
    "          drop = config.drop,\n",
    "          num_classes = config.num_classes,\n",
    "          strides = config.strides,\n",
    "          sr_ratios = config.sr_ratios,\n",
    "          head_dim = config.head_dim,\n",
    "          mix_block_ratio = config.mix_block_ratio,\n",
    "          use_checkpoint = config.use_checkpoint)\n",
    "        else:\n",
    "          print('Initialized with pretrained weights:')\n",
    "          self.model = MedViT_large(use_checkpoint = config.use_checkpoint)\n",
    "          self.model.proj_head = nn.Linear(1024, 5)        \n",
    "\n",
    "    def forward(self, pixel_values, labels=None):\n",
    "        logits = self.model(pixel_values)\n",
    "        if labels is not None:\n",
    "            loss = torch.nn.functional.cross_entropy(logits, labels)\n",
    "            return {\"loss\": loss, \"logits\": logits}\n",
    "        return {\"logits\": logits}\n",
    "\n",
    "model = MedViTClassification.from_pretrained(f'../saved_models/{pretrained_model_name}')\n",
    "trainer = get_trainer(model, prepared_ds_test, compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88b1ddc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ids = np.random.choice(len(prepared_ds_test), size=100, replace=False)\n",
    "inv_sample_ids = np.setdiff1d(np.arange(len(prepared_ds_test)), sample_ids)\n",
    "val_ds = prepared_ds_test.select(sample_ids)\n",
    "test_ds = prepared_ds_test.select(inv_sample_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "846c9c14-ffbe-4ff9-b7c4-96dd7419bfb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48b4e25ccd084fbeafb642042077b0b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_ds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m trainer\u001b[38;5;241m.\u001b[39mlog_metrics(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics)\n\u001b[1;32m      3\u001b[0m json\u001b[38;5;241m.\u001b[39mdump(metrics, \u001b[38;5;28mopen\u001b[39m( \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../results/metrics_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m ) )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:3467\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3464\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3466\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3467\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3468\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3469\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3470\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   3471\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   3472\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3473\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3475\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3477\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:3719\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3715\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics(\n\u001b[1;32m   3716\u001b[0m             EvalPrediction(predictions\u001b[38;5;241m=\u001b[39mall_preds, label_ids\u001b[38;5;241m=\u001b[39mall_labels, inputs\u001b[38;5;241m=\u001b[39mall_inputs)\n\u001b[1;32m   3717\u001b[0m         )\n\u001b[1;32m   3718\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3719\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEvalPrediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3720\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3721\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/Projects/DeepLearning/Project_new/Diabetic-retinopathy-classification/notebooks/../validation_utils.py:209\u001b[0m, in \u001b[0;36mget_compute_metrics.<locals>.compute_metrics\u001b[0;34m(eval_pred)\u001b[0m\n\u001b[1;32m    202\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(labels, predictions)\n\u001b[1;32m    203\u001b[0m perclass_acc \u001b[38;5;241m=\u001b[39m calculate_per_class_accuracy(cm)\n\u001b[1;32m    205\u001b[0m result \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    206\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mmean([result_accuracy[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]]),\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkappa\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mmean([cohen_kappa_score(labels, predictions, weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquadratic\u001b[39m\u001b[38;5;124m\"\u001b[39m)]),\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mmean([f1_score(labels, predictions, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m)]),\n\u001b[0;32m--> 209\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mmean([\u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions_proba\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43movr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m]),\n\u001b[1;32m    210\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_0\u001b[39m\u001b[38;5;124m'\u001b[39m : perclass_acc[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    211\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_1\u001b[39m\u001b[38;5;124m'\u001b[39m : perclass_acc[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m    212\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_2\u001b[39m\u001b[38;5;124m'\u001b[39m : perclass_acc[\u001b[38;5;241m2\u001b[39m],\n\u001b[1;32m    213\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_3\u001b[39m\u001b[38;5;124m'\u001b[39m : perclass_acc[\u001b[38;5;241m3\u001b[39m],\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_4\u001b[39m\u001b[38;5;124m'\u001b[39m : perclass_acc[\u001b[38;5;241m4\u001b[39m],\n\u001b[1;32m    215\u001b[0m         }\n\u001b[1;32m    217\u001b[0m plot_confusion_matrix(labels, predictions, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    218\u001b[0m                 title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNormalized confusion matrix\u001b[39m\u001b[38;5;124m'\u001b[39m, file_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:634\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m multi_class \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti_class must be in (\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124movo\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124movr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 634\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_multiclass_roc_auc_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    638\u001b[0m     labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y_true)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:707\u001b[0m, in \u001b[0;36m_multiclass_roc_auc_score\u001b[0;34m(y_true, y_score, labels, multi_class, average, sample_weight)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# validation of the input y_score\u001b[39;00m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(\u001b[38;5;241m1\u001b[39m, y_score\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m--> 707\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget scores need to be probabilities for multiclass \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    709\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroc_auc, i.e. they should sum up to 1.0 over classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    710\u001b[0m     )\n\u001b[1;32m    712\u001b[0m \u001b[38;5;66;03m# validation for multiclass parameter specifications\u001b[39;00m\n\u001b[1;32m    713\u001b[0m average_options \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate(val_ds)\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "json.dump(metrics, open( f'../results/metrics_{pretrained_model_name}_{dataset_name}.json', 'w' ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5507f71",
   "metadata": {},
   "source": [
    "## MedViT with ECA attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4147f46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_name = 'MedViT512_tr35_stage6(3)_CCropSpot2HTrivAug_fastvitprepr_lr1e5'\n",
    "dataset_name = 'DDR'\n",
    "prepared_ds_test = custom_dataset(pretrained_model_name)\n",
    "compute_metrics = get_compute_metrics(pretrained_model_name, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a9b0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise a MedViT class\n",
    "import math\n",
    "from transformers import PreTrainedModel\n",
    "from MedViT.MedViT import MedViT, MedViT_large\n",
    "\n",
    "class ECALayer(nn.Module):\n",
    "    def __init__(self, channels, gamma=2, b=1):\n",
    "        super().__init__()\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        t = int(abs((math.log(channels, 2) + b) / gamma))\n",
    "        k = t if t % 2 else t + 1\n",
    "        self.conv = nn.Conv1d(1, 1, kernel_size=k, padding=(k - 1) // 2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        # Initializing the weights with a uniform distribution \n",
    "        nn.init.uniform_(self.conv.weight) \n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.avgpool(x)\n",
    "        y = self.conv(y.squeeze(-1).transpose(-1, -2)).transpose(-1, -2).unsqueeze(-1)\n",
    "        y = self.sigmoid(y)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "class MedViTClassification(PreTrainedModel):\n",
    "    config_class = MedViTConfig\n",
    "\n",
    "    def __init__(self, config, pretrained=False):\n",
    "        super().__init__(config)\n",
    "\n",
    "        if pretrained is False:\n",
    "          print('Initialized with random weights:')\n",
    "          self.model = MedViT(\n",
    "          stem_chs = config.stem_chs,\n",
    "          depths = config.depths,\n",
    "          path_dropout = config.path_dropout,\n",
    "          attn_drop = config.attn_drop,\n",
    "          drop = config.drop,\n",
    "          num_classes = config.num_classes,\n",
    "          strides = config.strides,\n",
    "          sr_ratios = config.sr_ratios,\n",
    "          head_dim = config.head_dim,\n",
    "          mix_block_ratio = config.mix_block_ratio,\n",
    "          use_checkpoint = config.use_checkpoint)\n",
    "\n",
    "        else:\n",
    "          print('Initialized with pretrained weights:')\n",
    "          self.model = MedViT_large(use_checkpoint = config.use_checkpoint)\n",
    "          self.model.proj_head = nn.Linear(1024, 5)\n",
    "\n",
    "          nn.init.uniform_(self.model.proj_head.weight)\n",
    "        \n",
    "        self.apply_attention()\n",
    "        self.check_freezing()\n",
    "        \n",
    "    def check_freezing(self):\n",
    "\n",
    "        # freeze some layers\n",
    "        for name, child in self.model.named_children():\n",
    "            for param in child.parameters():\n",
    "                if param.requires_grad == True:\n",
    "                    print(name)\n",
    "\n",
    "    def apply_attention(self):\n",
    "        self.model.features[6].e_mhsa = ECALayer(192)\n",
    "        self.model.features[11].e_mhsa = ECALayer(384)\n",
    "        self.model.features[16].e_mhsa = ECALayer(384)\n",
    "        self.model.features[21].e_mhsa = ECALayer(384)\n",
    "        \n",
    "        self.model.features[26].e_mhsa = ECALayer(384)\n",
    "        self.model.features[31].e_mhsa = ECALayer(384)\n",
    "        self.model.features[36].e_mhsa = ECALayer(384)\n",
    "        self.model.features[39].e_mhsa = ECALayer(768)\n",
    "\n",
    "    def freeze_layers(self):\n",
    "\n",
    "        # freeze some layers\n",
    "        for name, child in self.model.named_children():\n",
    "            for param in child.parameters():                    \n",
    "                param.requires_grad = False\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, pixel_values, labels=None):\n",
    "        logits = self.model(pixel_values)\n",
    "        if labels is not None:\n",
    "            loss = torch.nn.functional.cross_entropy(logits, labels)\n",
    "            return {\"loss\": loss, \"logits\": logits}\n",
    "        return {\"logits\": logits}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
