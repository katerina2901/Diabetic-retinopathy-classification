{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ViT training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JtILku8nlnu1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" # is need to train on 'hachiko'\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from typing import Tuple\n",
    "from typing import List\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "from datasets import Dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "from transformers import ViTImageProcessor\n",
    "from transformers import AutoImageProcessor\n",
    "from transformers import TrainingArguments\n",
    "from transformers import PretrainedConfig\n",
    "from transformers import PreTrainedModel\n",
    "from transformers import Trainer\n",
    "from transformers import ViTForImageClassification\n",
    "from transformers import EfficientNetImageProcessor, EfficientNetForImageClassification\n",
    "\n",
    "# import of custom functions\n",
    "from validation_utils import collate_fn, get_compute_metrics\n",
    "from data_utils import resample\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model to trian start from pretrained weights on Imagenet\n",
    "model_name_or_path = 'google/vit-base-patch16-224-in21k'\n",
    "\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    ignore_mismatched_sizes=True,\n",
    "    num_labels=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7WpehQWO0PFO"
   },
   "outputs": [],
   "source": [
    "# load dataset via csv table\n",
    "labelsTable = pd.read_csv('../mnt/local/data/kalexu97/trainLabels.csv') # initial table\n",
    "\n",
    "# add folder path\n",
    "root_dir = '../mnt/local/data/kalexu97/train'\n",
    "labelsTable['image_path'] = labelsTable['image'].apply(lambda x: os.path.join(root_dir, x+'.jpeg'))\n",
    "labelsTable['label'] = labelsTable['level']\n",
    "labelsTable = labelsTable.drop(columns=['image', 'level'], axis=1)\n",
    "\n",
    "# dataset is spliated to trian and test previously, and is constant for every training process\n",
    "test_dataset = pd.read_csv('test_dataset.csv')\n",
    "\n",
    "# subtract the test_dataset from the full dataset to get the train_dataset\n",
    "df = pd.concat([test_dataset, labelsTable])\n",
    "df = df.reset_index(drop=True)\n",
    "df_gpby = df.groupby(list(['image_path', 'label']))\n",
    "idx = [x[0] for x in df_gpby.groups.values() if len(x) == 1]\n",
    "\n",
    "train_dataset = df.reindex(idx).drop(columns=['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "id": "FVFGrO9X0PFO",
    "outputId": "d12ae911-a688-4dae-f399-071763564f7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: length: 19460\n",
      "1: length: 19460\n",
      "2: length: 19460\n",
      "3: length: 19460\n",
      "4: length: 19460\n",
      "N_added_rows:  26953\n",
      "N_all_rows:  28100\n",
      "Ratio of used rows:  0.9591814946619217\n"
     ]
    }
   ],
   "source": [
    "# RUS for major classes, ROS for minor classes\n",
    "# number of items in each class is equal to \n",
    "#           ratio * len(most_minor_dataset) \n",
    "\n",
    "# oversampling just repeating minority class items\n",
    "# enought times to be equal to major dataset in size\n",
    "train_dataset = resample(train_dataset, ratio = 35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Augmentaion, Preprocessing, Post-Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import CenterCrop, Spot, RandomSharpen, Blur, Halo, Hole\n",
    "\n",
    "# define preprocessor\n",
    "image_processor = AutoImageProcessor.from_pretrained(model_name_or_path)\n",
    "\n",
    "# for some models it is possible to change input size between training stage\n",
    "image_processor.size['height'] = 224\n",
    "image_processor.size['width'] = 224\n",
    "\n",
    "# Pre-Augmetations\n",
    "_transforms_train = T.Compose([\n",
    "    T.RandomHorizontalFlip(p = 0.5),\n",
    "    T.RandomVerticalFlip(p = 0.5),\n",
    "    CenterCrop(),\n",
    "    T.Resize((260, 260), interpolation=T.InterpolationMode.BICUBIC),\n",
    "    T.RandomCrop(224, padding_mode='symmetric', pad_if_needed=True),\n",
    "    T.TrivialAugmentWide(),\n",
    "    # Sharpness(),\n",
    "    # Blur()\n",
    "])\n",
    "\n",
    "# Post-Augmentations\n",
    "post_transforms_train = T.Compose([\n",
    "    Spot(size=224),\n",
    "    Halo(size=224),\n",
    "    Hole(size=224),\n",
    "    \n",
    "])\n",
    "\n",
    "# Pre-Augmentaions for test_dataset\n",
    "_transforms_test = T.Compose([\n",
    "    CenterCrop(),\n",
    "])\n",
    "\n",
    "\n",
    "def load_image(path_image, label, mode):\n",
    "    \"\"\"\n",
    "    The function loads image from path and make Pre-Augmentation.\n",
    "    \"\"\"\n",
    "    image = Image.open(path_image)\n",
    "\n",
    "    if mode == 'train':\n",
    "        image = _transforms_train(image)\n",
    "        return image\n",
    "        \n",
    "    else:\n",
    "        image = _transforms_test(image)\n",
    "        return image\n",
    "        \n",
    "\n",
    "def func_transform(examples):\n",
    "    \"\"\"\n",
    "    The function is used to preprocess train dataset.\n",
    "    \"\"\"\n",
    "    # pre-augmentation and preprocessing\n",
    "    inputs = image_processor([load_image(path, lb, 'train')\n",
    "                                for path, lb in zip(examples['image_path'], examples['label'])], return_tensors='pt')\n",
    "    \n",
    "    # post-augmentation\n",
    "    inputs_post = [post_transforms_train(img_tensor) for img_tensor in inputs['pixel_values']]\n",
    "    inputs['pixel_values'] = inputs_post\n",
    "    inputs['label'] = examples['label']\n",
    "\n",
    "    return inputs\n",
    "\n",
    "def func_transform_test(examples):\n",
    "    \"\"\"\n",
    "    The function is used to preprocess test dataset.\n",
    "    \"\"\"\n",
    "    # pre-augmentation and preprocessing\n",
    "    inputs = image_processor([load_image(path, lb, 'test')\n",
    "                                for path, lb in zip(examples['image_path'], examples['label'])], return_tensors='pt')\n",
    "    inputs['label'] = examples['label']\n",
    "    \n",
    "    return inputs\n",
    "\n",
    "# to dataset\n",
    "train_ds = Dataset.from_pandas(train_dataset, preserve_index=False)\n",
    "test_ds = Dataset.from_pandas(test_dataset, preserve_index=False)\n",
    "\n",
    "# apply preprocessing\n",
    "prepared_ds_train = train_ds.with_transform(func_transform)\n",
    "prepared_ds_test = test_ds.with_transform(func_transform_test)\n",
    "\n",
    "# for sorted datasets shuffling can be usefull\n",
    "prepared_ds_train = prepared_ds_train.shuffle(seed=42)\n",
    "prepared_ds_test = prepared_ds_test.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split test_dataset to val_dataset and test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_dataset is alse defined previously, so we just need to load its indexes\n",
    "with open('test_indeces.npy', 'rb') as f:\n",
    "    sample_ids = np.load(f)\n",
    "    inv_sample_ids = np.load(f)\n",
    "\n",
    "val_ds = prepared_ds_test.select(sample_ids)\n",
    "test_ds = prepared_ds_test.select(inv_sample_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "WSYrUDeZpAj6"
   },
   "outputs": [],
   "source": [
    "# run_name is used to log metadata in wandb for tracking\n",
    "r_name = \"vit384(16)_rot_4\"\n",
    "\n",
    "# define the function to compute metrics\n",
    "compute_metrics = get_compute_metrics(r_name, 'EyE', save_cm=False)\n",
    "\n",
    "# arguments for training\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./ViT-base\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    logging_steps=50,\n",
    "\n",
    "    save_steps=50,\n",
    "    eval_steps=50,\n",
    "    save_total_limit=3,\n",
    "    \n",
    "    report_to=\"wandb\",  # enable logging to W&B\n",
    "    run_name=r_name,  # name of the W&B run (optional)\n",
    "    \n",
    "    remove_unused_columns=False,\n",
    "    dataloader_num_workers = 16,\n",
    "    # lr_scheduler_type = 'constant_with_warmup', # 'constant', 'cosine'\n",
    "    \n",
    "    learning_rate=1e-5,\n",
    "    # label_smoothing_factor = 0.6,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=4,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    warmup_ratio=0.02,\n",
    "    \n",
    "    metric_for_best_model=\"kappa\", # select the best model via metric kappa\n",
    "    greater_is_better = True,\n",
    "    load_best_model_at_end=True,\n",
    "    \n",
    "    push_to_hub=False\n",
    ")\n",
    "\n",
    "# define trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=prepared_ds_train,\n",
    "    eval_dataset=val_ds,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in some cases we can continue training from some checkpoint\n",
    "\n",
    "# trainer.num_train_epochs = trainer.num_train_epochs + 5\n",
    "# trainer.learning_rate=1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "HzZeFonHq7Nb",
    "outputId": "4bb05cc3-86ee-4f97-9e62-9cc08b6ebe8e"
   },
   "outputs": [],
   "source": [
    "# trainer.train(\"./MedViT-base/checkpoint-22800\")\n",
    "train_results = trainer.train()\n",
    "trainer.save_model()\n",
    "trainer.log_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate on test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "id": "1b0XanyKvYco",
    "outputId": "ba715f3f-1acd-40b5-f275-80b6ad64e716"
   },
   "outputs": [],
   "source": [
    "metrics = trainer.evaluate(test_ds)\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "trainer.save_metrics(\"eval\", metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model weights and preprocessor configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JCo8lKEDvaI9"
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(f\"./saved_models/{r_name}\", from_pt=True)\n",
    "image_processor.save_pretrained(f\"./saved_models/{r_name}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
